{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Digital imagery and image processing\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    " <td>\n",
    "   <a href=https://colab.research.google.com/github/KMarkert/ee-workshop-esa2023/blob/main/notebooks/03_digital_imagery_and_image_processing.ipynb>\n",
    "       <img src=https://cloud.google.com/ml-engine/images/colab-logo-32px.png alt=\"Colab logo\">\n",
    "    Run in Colab\n",
    "   </a>\n",
    " </td>\n",
    " <td>\n",
    "   <a href=https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/KMarkert/ee-workshop-esa2023/main/notebooks/03_digital_imagery_and_image_processing.ipynb>\n",
    "       <img src=https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32 alt=\\\"Vertex AI logo\\\">\n",
    "     Open in Vertex AI Workbench\n",
    "   </a>\n",
    " </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRpK6EuaxAOd"
   },
   "source": [
    "**Purpose:** The purpose of this lab is to demonstrate concepts of digital image processing.  You will be introduced to methods for image smoothing, sharpening, edge detection, morphological processing, texture analysis, resampling and reprojection.  At the completion of the lab, you will be able to identify image processing operators that may be useful in extracting information of interest for your image analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxAQMzws1L3C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import ee api and geemap package\n",
    "import ee\n",
    "import geemap\n",
    "from pprint import pprint\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmLQLlUR1QR6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try to initalize an ee session\n",
    "# if not authenticated then run auth workflow and initialize\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5pt1kImxbxh"
   },
   "source": [
    "## Digital image visualization\n",
    "\n",
    "You've learned about how an image stores pixel data in each band as DNs and how the pixels are organized spatially.  When you add an image to the map, Earth Engine handles the spatial display for you by recognizing the projection and putting all the pixels in the right place.  However, you must specify how to stretch the DNs to make an 8-bit display image (e.g. the min and max visualization parameters).  Specifying min and max applies (where $DN'$ is the displayed value):\n",
    "\n",
    "$DN' = (DN - min) * 255 / (max - min)$\n",
    "\n",
    "This visualization process is linear, we can apply transformations on the displayed values to highlight specific features of the image or values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekJ8Q6dfYyrR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in a Landsat 8 image directly \n",
    "# this is the image we will be using for processing\n",
    "image = (\n",
    "    ee.Image('LANDSAT/LC08/C01/T1_SR/LC08_044034_20140318')\n",
    "    .select(\"B[1-7]\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VAjK-Hv83UK"
   },
   "source": [
    "Some of the image processing we are going to explore requires us to \"force\" Earth Engine to process at a specific projection and scale so we are going to set the image projection to a variable for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItwfAjq58s-5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract out the projection information\n",
    "proj = image.projection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mK8nkRTI19uz"
   },
   "source": [
    "### Gamma correction\n",
    "\n",
    "The Gamma correction is a nonlinear operation used to scale the DN values for visualization. The gamma correction can be applied mathematically ($DN' = DN^\\gamma$), however, we can apply it simply providing the `gamma` keyword for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfNQbfqO2AU5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "# Display gamma stretches of the input image.\n",
    "Map.addLayer(image.visualize(bands=[\"B7\",\"B5\",\"B3\"], min=0, max=5500, gamma=0.5), {}, 'gamma = 0.5');\n",
    "Map.addLayer(image.visualize(bands=[\"B7\",\"B5\",\"B3\"], min=0, max=5500, gamma=1.5), {}, 'gamma = 1.5');\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "311i4Iubz0GK"
   },
   "source": [
    "Note that gamma is supplied as an argument to `image.visualize()` so that you can click on the map to see the difference in pixel values (try it!).  It's possible to specify gamma, min and max to achieve other unique visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQ1wEiZY3419"
   },
   "source": [
    "### Histogram equalization\n",
    "\n",
    "Histogram equalization is a method in image processing of contrast adjustment using the image's histogram.\n",
    "\n",
    "To apply a histogram equalization stretch, use the `sldStyle()` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rXZ96zb0DTD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a RasterSymbolizer element with '_enhance_' for a placeholder.\n",
    "histogram_sld = \"\"\"\n",
    "  <RasterSymbolizer>\n",
    "    <ContrastEnhancement><Histogram/></ContrastEnhancement>\n",
    "    <ChannelSelection>\n",
    "      <RedChannel>\n",
    "        <SourceChannelName>B7</SourceChannelName>\n",
    "      </RedChannel>\n",
    "      <GreenChannel>\n",
    "        <SourceChannelName>B5</SourceChannelName>\n",
    "      </GreenChannel>\n",
    "      <BlueChannel>\n",
    "        <SourceChannelName>B3</SourceChannelName>\n",
    "      </BlueChannel>\n",
    "    </ChannelSelection>\n",
    "  </RasterSymbolizer>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KN30AbRz4cm4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "# Display visualization stretches of the input image.\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(image.sldStyle(histogram_sld), {}, 'Equalized');\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfbQd1RmxiTx"
   },
   "source": [
    "## Band math\n",
    "\n",
    "Band math can be performed using operators like `add()` and `subtract()`, but for complex computations with more than a couple of terms, the `expression()` function provides a good alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS9mRkK9JhiT"
   },
   "source": [
    "### Normalized Difference Vegetation Index\n",
    "\n",
    "As a simple example for using band math is calculating the Normalized Difference Vegetation Index (NDVI) using Landsat imagery, where `add()`, `subtract()`, and `divide()` operators are used:\n",
    "\n",
    "$NDVI = \\frac{NIR-Red}{NIR + Red}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsEDj5EIximr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "nir = image.select(\"B5\")\n",
    "red = image.select(\"B4\")\n",
    "\n",
    "ndvi = nir.subtract(red).divide(nir.add(red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLMbNe7zKzKi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display original and NDVI images.\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original')\n",
    "Map.addLayer(ndvi, {\"min\":0,\"max\":1}, 'NDVI');\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8l20_5RKYSw"
   },
   "source": [
    "For the complete list of mathematical operators handling basic arithmetic, trigonometry, exponentiation, rounding, casting, bitwise operations and more, see the [API documentation](https://developers.google.com/earth-engine/apidocs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfX-EkNEygua"
   },
   "source": [
    "### Expression example\n",
    "\n",
    "To implement more complex mathematical expressions, consider using `image.expression()`, which parses a text representation of a math operation. The following example uses `expression()` to compute the [Enhanced Vegetation Index (EVI)](https://en.wikipedia.org/wiki/Enhanced_vegetation_index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIbIUfqsyqcs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "evi = image.expression(\n",
    "    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "        'NIR': image.select('B5'),\n",
    "        'RED': image.select('B4'),\n",
    "        'BLUE': image.select('B2')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpuFW2lIMG39",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display original and NDVI images.\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original')\n",
    "Map.addLayer(ndvi, {\"min\":0,\"max\":1}, 'NDVI')\n",
    "Map.addLayer(evi, {\"min\":0,\"max\":2}, 'EVI')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_UROKCfJKCA"
   },
   "source": [
    "The first argument to `expression()` is the textual representation of the math operation, the second argument is a dictionary where the keys are variable names used in the expression and the values are the image bands to which the variables should be mapped. Bands in the image may be referred to as `b(\"band name\")` or `b(index)`, for example `b(0)`, instead of providing the dictionary. Bands can be defined from images other than the input when using the band map dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7Nfz4EEcLS3"
   },
   "source": [
    "## Zonal statistics\n",
    "\n",
    "To get statistics of pixel values in a region of an ee.Image, use `image.reduceRegion()`. This reduces all the pixels in the region(s) to a statistic or other compact representation of the pixel data in the region (e.g. histogram). The region is represented as a Geometry, which might be a polygon, containing many pixels, or it might be a single point, in which case there will only be one pixel in the region.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "An2O4wh2cQQC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a combined reducer that will calculate mean and standard deviation \n",
    "my_reducer = ee.Reducer.mean().combine(ee.Reducer.stdDev(), None, True)\n",
    "\n",
    "# calculate mean and stdDev over entire image\n",
    "image_stats = image.reduceRegion(\n",
    "    reducer = my_reducer,\n",
    "    geometry = image.geometry(),\n",
    "    scale = 120,\n",
    "    maxPixels = 1e10,\n",
    "    bestEffort = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77vMs4_-d5an"
   },
   "source": [
    "Note here that the reducers are combined as it is more efficient to combine reducers if you need multiple statistics (e.g. mean and standard deviation) from a single input (e.g. an image region). ([Combining reducers best practice](https://developers.google.com/earth-engine/guides/best_practices#combine-reducers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9L7txGuecqZs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the statistics\n",
    "JSON(image_stats.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qEM54KncmoD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the dictionary to an image\n",
    "# band names will be the keys\n",
    "# bands will be constant values\n",
    "statistics_image = image_stats.toImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZu73qzadApx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract out the mean and standard deviation bands\n",
    "# to two seperate images\n",
    "mean_image = statistics_image.select(\"B.*_mean\")\n",
    "stdDev_image = statistics_image.select(\"B.*_stdDev\")\n",
    "\n",
    "# calculate z-score\n",
    "zscore = image.select(\"B.*\").subtract(mean_image).divide(stdDev_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CDwFIMdcpzc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display original and scaled images.\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original')\n",
    "Map.addLayer(zscore, {\"bands\": [\"B7\",\"B5\",\"B3\"],\"min\":-2.5,\"max\":2.5}, 'Std. Deviation Stretch')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1cTIKnRxdiO",
    "tags": []
   },
   "source": [
    "## Neighborhood operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM6xiAgVOJYa"
   },
   "source": [
    "## Image Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKnQPtFmytvn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alternate approach for calculating a normalized difference\n",
    "mndwi = image.normalizedDifference([\"B3\",\"B6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hixdyw_0OUtF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 0.1 # define a threshold to segment the image\n",
    "water = mndwi.gt(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOP8BRvOOMhK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(mndwi, {\"min\": -0.5, \"max\": 1,}, 'MNDWI');\n",
    "Map.addLayer(water, {\"min\": 0, \"max\": 1, \"palette\":[\"black\",\"lightblue\"]}, 'Water');\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAPfCb_7yALQ"
   },
   "source": [
    "## Compositing\n",
    "\n",
    "Compositing is the process of taking multiple images and making a single representative image using some statistical reduction. There are multiple ways to achieve composites and an active research area. Really the composite apporach you use depends on the data and application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XonDCgVzXMP"
   },
   "source": [
    "### Mean vs Median Composite\n",
    "\n",
    "Mean/Medain compositing is very common and this illustrates the general workflow to create such a composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8K-avD1dyFqV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in an image collection and filter by space and time\n",
    "l8 = (\n",
    "    ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "    .filterDate('2021-01-01', '2022-01-01')\n",
    "    .filterBounds(ee.Geometry.Rectangle([-124.736342, 24.521208, -66.945392, 49.382808]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-jAXSiuzmd6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first step is to usually mask out poor quality observations\n",
    "# this function takes a landsat image and reads the QA band \n",
    "# to determine which pixels are good or bad then\n",
    "# masks (sets to nodata) poor quality pixels\n",
    "def qa(img):\n",
    "    # Bits 3, 4 and 5 are cloud shadow, snow and cloud, respectively.\n",
    "    cloudshadow_bit_mask = 1 << 3\n",
    "    snow_bit_mask = 1 << 4\n",
    "    clouds_bit_mask = 1 << 5\n",
    "    \n",
    "\n",
    "    # Get the pixel QA band.\n",
    "    qa = img.select('pixel_qa')\n",
    "\n",
    "    # All flags should be set to zero, indicating clear conditions.\n",
    "    cloudshadow_mask = qa.bitwiseAnd(cloudshadow_bit_mask).eq(0)\n",
    "    snow_mask = qa.bitwiseAnd(snow_bit_mask).eq(0)\n",
    "    cloud_mask = qa.bitwiseAnd(clouds_bit_mask).eq(0)\n",
    "\n",
    "    # combine the masks to identify where it is clear in all cases\n",
    "    mask = cloudshadow_mask.And(snow_mask).And(cloud_mask)\n",
    "\n",
    "    # Return the masked image, scaled to reflectance, without the QA bands.\n",
    "    return (\n",
    "        img.updateMask(mask)\n",
    "        .select(\"B[0-9]*\")\n",
    "        .copyProperties(img, [\"system:time_start\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8YD4gfl1NYK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the QA function to mask poor quality observations\n",
    "l8_qa = l8.map(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRTSgiXo1WYp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply mean reductions\n",
    "l8_mean_comp = l8_qa.reduce(ee.Reducer.mean())\n",
    "\n",
    "# apply median reduction\n",
    "l8_median_comp = l8_qa.median()\n",
    "\n",
    "# this is the equivalent calling .reduce() with \n",
    "# a median reducer\n",
    "# image.reduce(ee.Reducer.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lHVzx2P2je1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(l8_median_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Median Composite');\n",
    "Map.addLayer(l8_mean_comp, {\"bands\": [\"B7_mean\",\"B5_mean\",\"B3_mean\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Mean Composite');\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpjqGz0gzh0q"
   },
   "source": [
    "### Quality band composite\n",
    "\n",
    "Sometimes it is useful to create a composite based on a specific variable that is of interest. For example, if we are interested in creating an image of peak vegetation per-pixel we can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_ndvi_band(image):\n",
    "    ndvi = image.normalizedDifference(['B5','B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1Mjac025gVx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the ndvi function to each image\n",
    "l8_ndvi = l8_qa.map(add_ndvi_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVu3GTrk5pG2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a composite using the maximum ndvi value\n",
    "l8_ndvi_comp = l8_ndvi.qualityMosaic(\"NDVI\")\n",
    "l8_max_comp = l8_ndvi.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqaRV3tN5vnw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 10)\n",
    "\n",
    "Map.addLayer(l8_median_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Median Composite');\n",
    "Map.addLayer(l8_mean_comp, {\"bands\": [\"B7_mean\",\"B5_mean\",\"B3_mean\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Mean Composite');\n",
    "Map.addLayer(l8_ndvi_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'NDVI Composite');\n",
    "Map.addLayer(l8_max_comp, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Max Composite');\n",
    "\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R28uLWbRzC_n"
   },
   "source": [
    "These are examples of compositing techniques. Again, how you composite your imagery will be based on your application. A well-known example of a peer-reviewed compositing approach is the Best Avaiable Pixel (BAP) composite ([White et al., 2014](https://www.tandfonline.com/doi/full/10.1080/07038992.2014.945827))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HA8hFogLdbL"
   },
   "source": [
    "It is worth noting that composite images created by reducing an image collection are able to produce pixels in any requested projection and therefore have no fixed output projection. Instead, composites have the [default projection](https://developers.google.com/earth-engine/guides/projections#the-default-projection) of WGS-84 with 1-degree resolution pixels. Composites with the default projection will be computed in whatever output projection is requested. A request occurs by displaying the composite, or by explicitly specifying a projection/scale as in an aggregation such as `reduceRegion()` or `ee.batch.Export`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dt1e35M9x-Pk"
   },
   "source": [
    "## Resampling and Reprojection\n",
    "\n",
    "Earth Engine makes every effort to handle projection and scale so that you don't have to.  However, there are occasions where an understanding of projections is important to get the output you need.  As an example, it's time to demystify the `reproject()` calls in the previous examples.  Earth Engine requests inputs to your computations in the projection and scale of the output.  The map created using `geemap` has a [Maps Mercator projection](http://epsg.io/3857).  The scale is determined from the map's zoom level.  When you add something to this map, Earth Engine secretly reprojects the input data to Mercator, resampling (with nearest neighbor) to screen resolution pixels based on the map's zoom level, then does all the computations with the reprojected, resampled imagery.  In the previous examples, the `reproject()` calls force the computations to be done at the resolution of the input pixels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxGNHnCJTzNB"
   },
   "source": [
    "To demonstrate the resampling done by Earth Engine, we are going to re-run the edge detection and display with and without the reprojection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeiQLAetx_NQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate edges without reprojection\n",
    "ndvi_stddev = ndvi.reduceNeighborhood(\n",
    "    reducer=ee.Reducer.stdDev(),\n",
    "    kernel = ee.Kernel.square(4.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# force processing at native projection for visualization\n",
    "ndvi_stddev_reprojected = ndvi_stddev.reproject(proj, None, proj.nominalScale()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDZpUkbBUKOM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.centerObject(image, 11)\n",
    "\n",
    "# Display gamma stretches of the input image.\n",
    "Map.addLayer(image, {\"bands\": [\"B7\",\"B5\",\"B3\"], \"min\": 0, \"max\": 5500, \"gamma\": 1.5}, 'Original');\n",
    "Map.addLayer(ndvi_stddev, {\"min\": 0, \"max\": 1,}, 'NDVI std dev with variable resolution');\n",
    "Map.addLayer(ndvi_stddev_reprojected, {\"min\": 0, \"max\": 1,}, 'NDVI std dev at native resolution');\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sagthgg7Uxvz"
   },
   "source": [
    "What's happening here is that the projection specified in `reproject()` (like we used earlier) propagates backwards to the input, forcing all the computations to be performed in that projection.  If you don't specify, the computations are performed in the projection and scale of the map (Mercator) at screen resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SF6Tbx2rU-h4"
   },
   "source": [
    "You can control how Earth Engine resamples the input with `resample()`.  By default, all resampling is done with nearest neighbor.  To change that, call `resample()` on the inputs.  Compare the input image, resampled to screen resolution with a bilinear and bicubic resampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09YAZo1UVQOb"
   },
   "source": [
    "Try zooming in and out, comparing to the input image resampled with nearest neighbor (i.e. without `resample()` called on it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1nD64GcTlf-"
   },
   "source": [
    "**_You should rarely, if ever, have to use `reproject()` and `resample()`._** Do not use `reproject()` or `resample()` unless absolutely necessary.  They are only used here for demonstration purposes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 3 - Digital imagery and image processing.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
