{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZYHAFWoLFza"
   },
   "source": [
    "# Species Distribution Modeling on Earth Engine\n",
    "\n",
    "<table align=\"left\">\n",
    " <td>\n",
    "   <a href=https://colab.research.google.com/github/KMarkert/ee-workshop-esa2023/blob/main/notebooks/04_species_distribution_modeling_ee.ipynb>\n",
    "       <img src=https://cloud.google.com/ml-engine/images/colab-logo-32px.png alt=\"Colab logo\">\n",
    "    Run in Colab\n",
    "   </a>\n",
    " </td>\n",
    " <td>\n",
    "   <a href=https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/KMarkert/ee-workshop-esa2023/main/notebooks/04_species_distribution_modeling_ee.ipynb>\n",
    "       <img src=https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32 alt=\\\"Vertex AI logo\\\">\n",
    "     Open in Vertex AI Workbench\n",
    "   </a>\n",
    " </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:** The purpose of this lab is to demonstrate an ecological workflow for species distribution modeling using Earth Engine.  This will be use concepts from previous labs such as filtering, compositing, and image processing to create a. Futhermore, you will be introduced to exports for storing intermideate data and results as well as a classification workflow using a familiar ecological model, MaxEnt. At the completion of the lab, you will be able to walk through an end-to-end species distribition workflow using Earth Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDFN4DWrPXK4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook in Colab, run this cell to install geemap. \n",
    "# This allows for you to use interactive maps with Earth Engine.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If on Vertex AI Workbench, then don't execute this code\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if not os.path.exists(\"/opt/deeplearning/metadata/env_version\") and not os.getenv(\n",
    "    \"DL_ANACONDA_HOME\"\n",
    "):\n",
    "    if IS_COLAB:\n",
    "        !pip install geemap -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKYehudqjuy4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "import math\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "from geemap import colormaps as cmaps\n",
    "import google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_b8_Y9XOTZw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    print('Authenticating using Colab auth...')\n",
    "    # Authenticate to populate Application Default Credentials in the Colab VM.\n",
    "    google.colab.auth.authenticate_user()\n",
    "    # Create credentials needed for accessing Earth Engine.\n",
    "    credentials, auth_project_id = google.auth.default()\n",
    "    PROJECT = input('Enter your Google Cloud Project ID: ')\n",
    "    # Initialize Earth Engine.\n",
    "    ee.Initialize(credentials,project=PROJECT)\n",
    "    \n",
    "else:\n",
    "    print(\"Authenticating using Notebook auth...\")\n",
    "    if os.path.exists(ee.oauth.get_credentials_path()) is False:\n",
    "        ee.Authenticate()\n",
    "    else:\n",
    "        print('\\N{check mark} '\n",
    "              'Previously created authentication credentials were found.')\n",
    "    PROJECT=None\n",
    "    ee.Initialize()\n",
    "\n",
    "print('\\N{check mark} Successfully initialized!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking data\n",
    "\n",
    "A key component to species distribution modeling is understanding where the species have been so that we can understand the environmental factors that may influence where a particular species lives and migrates to.\n",
    "\n",
    "[Movebank](https://www.movebank.org/cms/movebank-main) is a great repository for accessing tracking data. For this example we will use the GPS tracking of bobcats and coyotes in northern Washington data from [Prugh et al., 2023](https://doi.org/10.1126/science.adf2472). This data has downaloded from Movebank been formatted for use with Earth Engine and ingested for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irHNtrZBPatE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# access the bobcat/coyote tracking data from Earth Engine asset\n",
    "tracking_data = ee.FeatureCollection('projects/ee-kmarkert-demo/assets/GPS_tracking_bobcats_coyotes_WA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "db5w_lo1md6y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# do some formatting to add a timestamp column\n",
    "tracking_data = (\n",
    "    tracking_data\n",
    "    .map(lambda x: ee.Feature(x).set('millis', ee.Date(ee.Feature(x).get('system:time_start')).millis()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTQJL7dbjx3Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter out data for different species\n",
    "coyotes = tracking_data.filter(\n",
    "  ee.Filter.eq(\"individual-taxon-canonical-name\", \"Canis latrans\")\n",
    ")\n",
    "bobcat = tracking_data.filter(\n",
    "  ee.Filter.eq(\"individual-taxon-canonical-name\", \"Lynx rufus\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9BzkTpbhS2S",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display the locations\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.addLayer(coyotes, {\"color\":\"red\"}, \"Coyotes\")\n",
    "Map.addLayer(bobcat, {\"color\":\"blue\"}, \"Bobcat\")\n",
    "\n",
    "Map.centerObject(tracking_data, 10)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Ig1PtbARNWD7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Choose your species\n",
    "\n",
    "species = \"Bobcat\" #@param [\"Bobcat\", \"Coyote\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ey9CpjyxpcJa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the correct distribution data based on species common name of interest\n",
    "if species.lower() == \"bobcat\":\n",
    "    species_locations = bobcat.randomColumn().limit(5000,'random')\n",
    "elif species.lower() == \"coyote\":\n",
    "    species_locations = coyotes.randomColumn().limit(5000,'random')\n",
    "else:\n",
    "    raise ValueError(\"value for `species` not recongnized, options are 'Bobcat' or 'Coyote'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c2T6hfkQwYx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the min/max dates from the collection so that we can composite imagery for the valid dates\n",
    "dates = (\n",
    "    tracking_data\n",
    "    .aggregate_array('system:time_start')\n",
    "    .map(lambda x: ee.Date(x).format('YYYY-MM-01'))\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "start_date = dates.reduce(ee.Reducer.min())\n",
    "end_date = dates.reduce(ee.Reducer.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQ3wa8GlXr-E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to convert qa bit image to flag\n",
    "def extract_bits(image, start, end=None, new_name=None):\n",
    "    \"\"\"Function to conver qa bits to binary flag image\n",
    "\n",
    "    args:\n",
    "        image (ee.Image): qa image to extract bit from\n",
    "        start (int): starting bit for flag\n",
    "        end (int | None, optional): ending bit for flag, if None then will only use start bit. default = None\n",
    "        new_name (str | None, optional): output name of resulting image, if None name will be {start}Bits. default = None\n",
    "\n",
    "    returns:\n",
    "        ee.Image: image with extract bits\n",
    "    \"\"\"\n",
    "\n",
    "    newname = new_name if new_name is not None else f\"{start}Bits\"\n",
    "\n",
    "    if (start == end) or (end is None):\n",
    "        # perform a bit shift with bitwiseAnd\n",
    "        return image.select([0], [newname]).bitwiseAnd(1 << start)\n",
    "    else:\n",
    "        # Compute the bits we need to extract.\n",
    "        pattern = 0\n",
    "        for i in range(start, end):\n",
    "            pattern += int(math.pow(2, i))\n",
    "\n",
    "        # Return a single band image of the extracted QA bits, giving the band\n",
    "        # a new name.\n",
    "        return image.select([0], [newname]).bitwiseAnd(pattern).rightShift(start)\n",
    "\n",
    "def preprocess_viirs(image):\n",
    "    \"\"\"Custom QA masking method for VIIRS VNP09GA dataset\"\"\"\n",
    "    cloudMask = extract_bits(\n",
    "        image.select(\"QF1\"), 2, end=3, new_name=\"cloud_qa\"\n",
    "    ).lt(1)\n",
    "    shadowMask = extract_bits(\n",
    "        image.select(\"QF2\"), 3, new_name=\"shadow_qa\"\n",
    "    ).Not()\n",
    "    snowMask = extract_bits(image.select(\"QF2\"), 5, new_name=\"snow_qa\").Not()\n",
    "    sensorZenith = image.select(\"SensorZenith\").abs().lt(6000)\n",
    "\n",
    "    qa_mask = cloudMask.And(shadowMask).And(sensorZenith)\n",
    "\n",
    "    ndvi = image.normalizedDifference(['I2', 'I1']).rename('NDVI')\n",
    "\n",
    "    return (\n",
    "        image.select('(M|I).*')\n",
    "        .addBands(ndvi)\n",
    "        .updateMask(qa_mask)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufiqPI92ddRU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in the VIIRS surface reflectance product\n",
    "# and apply the preprocessing function\n",
    "viirs = (\n",
    "    ee.ImageCollection(\"NOAA/VIIRS/001/VNP09GA\")\n",
    "    .filterDate(start_date, \"2023-08-01\")\n",
    "    .map(preprocess_viirs)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsnSyFojQbhl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dem = ee.Image(\"NASA/NASADEM_HGT/001\")\n",
    "bioclim = ee.Image(\"WORLDCLIM/V1/BIO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-5pmiHpIkLU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "absence_area = species_locations.geometry(1e4).bounds(1e4).buffer(1e6).difference(right = species_locations.geometry(1e2).buffer(500), maxError = 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gq7lGX8ah3Ky",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_locations(date):\n",
    "    \"\"\"Function to sample locations from a date\n",
    "\n",
    "    args:\n",
    "        date (ee.String): string date in YYYY-MM-dd format\n",
    "\n",
    "    returns:\n",
    "        ee.FeatureCollection: sampled locations for a given date\n",
    "    \"\"\"\n",
    "    start_date = ee.Date(date)\n",
    "    end_date = start_date.advance(1, \"month\")\n",
    "\n",
    "    tracks = species_locations.filter(\n",
    "        ee.Filter.rangeContains('millis',start_date.millis(), end_date.millis())\n",
    "    )\n",
    "\n",
    "    presence = tracks.map(lambda x: ee.Feature(x).set('presence',1))\n",
    "\n",
    "    absence = ee.FeatureCollection.randomPoints(absence_area, points=presence.size(), seed = start_date.millis(), maxError=1e3)\n",
    "    absence = absence.map(lambda x: ee.Feature(x).set('presence',0))\n",
    "\n",
    "    tracks = presence.merge(absence)\n",
    "\n",
    "    sample_img = (\n",
    "        viirs.filterDate(start_date, end_date).select(\"NDVI\").mean()\n",
    "        .addBands(dem.select('elevation'))\n",
    "        .addBands(bioclim)\n",
    "    )\n",
    "\n",
    "    samples = sample_img.sampleRegions(\n",
    "        collection=tracks,\n",
    "        scale=1000,\n",
    "        tileScale=16,\n",
    "        geometries=True,\n",
    "    )\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4i68dsQfjiMZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the ouptut to a Feature Collection and flatten\n",
    "samples = ee.FeatureCollection(dates.map(sample_locations)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the intermediate results\n",
    "\n",
    "Earth Engine has a limit to how long you can wait for one particular computation to finish, that is 5 minutes. To allow for longer running tasks that take a while to process, you can submit an export task that will run asyncronously. Here you will create an export task for the sampling so that can run a little longer and you can use the results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUUbUu1SbPqK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPORT_SAMPLES = False\n",
    "\n",
    "\n",
    "if EXPORT_SAMPLES:\n",
    "    \n",
    "    if PROJECT is None:\n",
    "        PROJECT = input('Enter your Google Cloud Project ID: ')\n",
    "    \n",
    "    sample_asset = f\"projects/{PROJECT}/assets/{species}_classifier_samples\"\n",
    "\n",
    "    task = ee.batch.Export.table.toAsset(\n",
    "        samples, \n",
    "        description=f'{species}_sample_export', \n",
    "        assetId=sample_asset)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can take some time depending on complexity of the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the distribution model\n",
    "\n",
    "To speed things up for demostration purposes, we will load in a pre-exported sample if you would like to use your samples you just exported at a later time, simply change the asset name to what was exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV4NrL1nlDD9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_fc = ee.FeatureCollection(f'projects/ee-kmarkert-demo/assets/{species}_classifier_samples\"\n",
    "# sample_fc = ee.FeatureCollection(sample_asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XMMEChQsxJP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get an image to use for prediction\n",
    "img =  (\n",
    "    viirs.filterDate(\"2019-04-01\",\"2019-05-01\").select(\"NDVI\").mean().resample()\n",
    "    .addBands(dem.select('elevation'))\n",
    "    .addBands(bioclim).resample()\n",
    ")\n",
    "\n",
    "# get the band names from the prediction image\n",
    "band_names = img.bandNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZShhqONOobbh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxent_classifier = (\n",
    "    ee.Classifier.amnhMaxent()\n",
    "    .setOutputMode('PROBABILITY')\n",
    "    .train(sample_fc,'presence', band_names)\n",
    ")\n",
    "\n",
    "classifier_explained = maxent_classifier.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiytRKCyuAe1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the classifier information\n",
    "JSON(classifier_explained.getInfo(), root='Contributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_bounds = sample_fc.reduceColumns(\n",
    "    ee.Reducer.minMax().repeat(\n",
    "        band_names.length()\n",
    "    ), \n",
    "    band_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the min and max for each variable to an image\n",
    "min_img = ee.Image.constant(prediction_bounds.get('min'))\n",
    "max_img = ee.Image.constant(prediction_bounds.get('max'))\n",
    "\n",
    "min_img = min_img.multiply(1.1)\n",
    "max_img = max_img.multiply(1.1)\n",
    "\n",
    "# threshold each variable and reduce to one band\n",
    "min_mask = img.gte(min_img).reduce(ee.Reducer.min())\n",
    "max_mask = img.lte(max_img).reduce(ee.Reducer.min())\n",
    "\n",
    "# combine the min/max mask into one image\n",
    "mask = min_mask.Or(max_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRX2osKHqi6d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the MaxEnt model on the image and mask the output to the bounds from training\n",
    "distribution_output = img.classify(maxent_classifier).updateMask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMhd7LPdqt72",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display the locations\n",
    "Map = geemap.Map()\n",
    "\n",
    "Map.addLayer(distribution_output, {'bands':'probability',\"palette\":cmaps.get_palette(\"magma\")}, f'{species} Distribution')\n",
    "\n",
    "Map.addLayer(min_mask,{}, \"min mask\",False)\n",
    "Map.addLayer(max_mask,{}, 'Max mask',False)\n",
    "Map.addLayer(mask,{}, 'combined mask',False)\n",
    "\n",
    "\n",
    "Map.addLayer(species_locations, {\"color\":\"red\"}, f\"{species} tracks\")\n",
    "\n",
    "Map.centerObject(species_locations, 8)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
